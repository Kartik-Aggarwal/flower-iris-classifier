{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/iris.csv\")\n",
    "del df['Id']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
      "0              5.1           3.5            1.4           0.2\n",
      "1              4.9           3.0            1.4           0.2\n",
      "2              4.7           3.2            1.3           0.2\n",
      "3              4.6           3.1            1.5           0.2\n",
      "4              5.0           3.6            1.4           0.2\n",
      "..             ...           ...            ...           ...\n",
      "145            6.7           3.0            5.2           2.3\n",
      "146            6.3           2.5            5.0           1.9\n",
      "147            6.5           3.0            5.2           2.0\n",
      "148            6.2           3.4            5.4           2.3\n",
      "149            5.9           3.0            5.1           1.8\n",
      "\n",
      "[150 rows x 4 columns] 0         Iris-setosa\n",
      "1         Iris-setosa\n",
      "2         Iris-setosa\n",
      "3         Iris-setosa\n",
      "4         Iris-setosa\n",
      "            ...      \n",
      "145    Iris-virginica\n",
      "146    Iris-virginica\n",
      "147    Iris-virginica\n",
      "148    Iris-virginica\n",
      "149    Iris-virginica\n",
      "Name: Species, Length: 150, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('Species', axis = 1)\n",
    "y = df.Species\n",
    "print(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "y = encoder.fit_transform(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scaler.transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=4,activation = 'relu', input_shape = [4,]))\n",
    "model.add(Dense(units=10,activation = 'relu' ))\n",
    "model.add(Dense(units=3,activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(patience = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 1.0818 - accuracy: 0.3500\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 113us/step - loss: 1.0808 - accuracy: 0.3500\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 59us/step - loss: 1.0799 - accuracy: 0.3500\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 52us/step - loss: 1.0791 - accuracy: 0.3500\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 47us/step - loss: 1.0782 - accuracy: 0.3500\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 64us/step - loss: 1.0771 - accuracy: 0.3500\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 128us/step - loss: 1.0762 - accuracy: 0.3500\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 110us/step - loss: 1.0754 - accuracy: 0.3500\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 200us/step - loss: 1.0743 - accuracy: 0.3500\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 136us/step - loss: 1.0733 - accuracy: 0.3500\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 143us/step - loss: 1.0725 - accuracy: 0.3500\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 60us/step - loss: 1.0713 - accuracy: 0.3500\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 142us/step - loss: 1.0703 - accuracy: 0.3500\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 47us/step - loss: 1.0693 - accuracy: 0.3500\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 29us/step - loss: 1.0682 - accuracy: 0.3500\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 1.0671 - accuracy: 0.3500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yash/Desktop/dl/dl/lib/python3.8/site-packages/keras/callbacks/callbacks.py:843: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 92us/step - loss: 1.0659 - accuracy: 0.3500\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 66us/step - loss: 1.0647 - accuracy: 0.3500\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 46us/step - loss: 1.0635 - accuracy: 0.3500\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 144us/step - loss: 1.0622 - accuracy: 0.3500\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 133us/step - loss: 1.0607 - accuracy: 0.3500\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 261us/step - loss: 1.0592 - accuracy: 0.3500\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 119us/step - loss: 1.0577 - accuracy: 0.3500\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 113us/step - loss: 1.0560 - accuracy: 0.3500\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 53us/step - loss: 1.0541 - accuracy: 0.3500\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 115us/step - loss: 1.0523 - accuracy: 0.3500\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 72us/step - loss: 1.0501 - accuracy: 0.3500\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 106us/step - loss: 1.0479 - accuracy: 0.3500\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 162us/step - loss: 1.0458 - accuracy: 0.3583\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 181us/step - loss: 1.0433 - accuracy: 0.3583\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 105us/step - loss: 1.0409 - accuracy: 0.3583\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 125us/step - loss: 1.0384 - accuracy: 0.3583\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 132us/step - loss: 1.0357 - accuracy: 0.3667\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 141us/step - loss: 1.0330 - accuracy: 0.3667\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 141us/step - loss: 1.0301 - accuracy: 0.3667\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 158us/step - loss: 1.0271 - accuracy: 0.3667\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 82us/step - loss: 1.0241 - accuracy: 0.3750\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 123us/step - loss: 1.0209 - accuracy: 0.3833\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 1.0175 - accuracy: 0.3917\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 64us/step - loss: 1.0141 - accuracy: 0.3917\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 63us/step - loss: 1.0106 - accuracy: 0.3917\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 98us/step - loss: 1.0070 - accuracy: 0.4083\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 154us/step - loss: 1.0035 - accuracy: 0.4333\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 117us/step - loss: 0.9998 - accuracy: 0.4417\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.9961 - accuracy: 0.4583\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 141us/step - loss: 0.9922 - accuracy: 0.4583\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 143us/step - loss: 0.9884 - accuracy: 0.4667\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 123us/step - loss: 0.9845 - accuracy: 0.4750\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 54us/step - loss: 0.9807 - accuracy: 0.4917\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 47us/step - loss: 0.9766 - accuracy: 0.4917\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 67us/step - loss: 0.9726 - accuracy: 0.5167\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 135us/step - loss: 0.9684 - accuracy: 0.5583\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 241us/step - loss: 0.9641 - accuracy: 0.5583\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 188us/step - loss: 0.9598 - accuracy: 0.5833\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 156us/step - loss: 0.9553 - accuracy: 0.5833\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 175us/step - loss: 0.9509 - accuracy: 0.6000\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 138us/step - loss: 0.9461 - accuracy: 0.6167\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 66us/step - loss: 0.9413 - accuracy: 0.6167\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 169us/step - loss: 0.9365 - accuracy: 0.6167\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 182us/step - loss: 0.9318 - accuracy: 0.6500\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.9267 - accuracy: 0.6583\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 83us/step - loss: 0.9217 - accuracy: 0.6583\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 59us/step - loss: 0.9166 - accuracy: 0.6667\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 100us/step - loss: 0.9114 - accuracy: 0.6667\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 157us/step - loss: 0.9061 - accuracy: 0.6667\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 106us/step - loss: 0.9010 - accuracy: 0.6833\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 101us/step - loss: 0.8957 - accuracy: 0.6833\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 126us/step - loss: 0.8905 - accuracy: 0.6833\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 166us/step - loss: 0.8853 - accuracy: 0.6833\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 151us/step - loss: 0.8802 - accuracy: 0.6833\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 111us/step - loss: 0.8751 - accuracy: 0.6833\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 62us/step - loss: 0.8701 - accuracy: 0.6833\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 94us/step - loss: 0.8651 - accuracy: 0.6917\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 90us/step - loss: 0.8604 - accuracy: 0.6917\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 146us/step - loss: 0.8553 - accuracy: 0.6917\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 104us/step - loss: 0.8504 - accuracy: 0.7000\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 159us/step - loss: 0.8456 - accuracy: 0.7000\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 230us/step - loss: 0.8410 - accuracy: 0.7000\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 187us/step - loss: 0.8363 - accuracy: 0.7083\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 142us/step - loss: 0.8316 - accuracy: 0.7083\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 72us/step - loss: 0.8271 - accuracy: 0.7083\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 130us/step - loss: 0.8226 - accuracy: 0.7083\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 89us/step - loss: 0.8183 - accuracy: 0.7083\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 78us/step - loss: 0.8139 - accuracy: 0.7083\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 173us/step - loss: 0.8096 - accuracy: 0.7083\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 122us/step - loss: 0.8054 - accuracy: 0.7083\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 119us/step - loss: 0.8013 - accuracy: 0.7083\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 112us/step - loss: 0.7973 - accuracy: 0.7083\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 189us/step - loss: 0.7932 - accuracy: 0.7083\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 126us/step - loss: 0.7891 - accuracy: 0.7083\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 39us/step - loss: 0.7853 - accuracy: 0.7083\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.7813 - accuracy: 0.7083\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 48us/step - loss: 0.7775 - accuracy: 0.7083\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 122us/step - loss: 0.7739 - accuracy: 0.7083\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 126us/step - loss: 0.7703 - accuracy: 0.7083\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 150us/step - loss: 0.7665 - accuracy: 0.7083\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 129us/step - loss: 0.7629 - accuracy: 0.7083\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 137us/step - loss: 0.7595 - accuracy: 0.7083\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 55us/step - loss: 0.7560 - accuracy: 0.7083\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 62us/step - loss: 0.7527 - accuracy: 0.7083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f244c32ef40>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = scaled_X_train,y = y_train, epochs = 100, callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f23f677d1f0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['loss','accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8009539842605591, 0.6333333253860474]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(scaled_X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=4,activation = 'relu', input_shape = [4,]))\n",
    "model.add(Dense(units=10,activation = 'relu' ))\n",
    "model.add(Dense(units=3,activation = 'softmax'))\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "150/150 [==============================] - 0s 480us/step - loss: 1.1826 - accuracy: 0.3333\n",
      "Epoch 2/200\n",
      "150/150 [==============================] - 0s 93us/step - loss: 1.1619 - accuracy: 0.3200\n",
      "Epoch 3/200\n",
      "150/150 [==============================] - 0s 92us/step - loss: 1.1419 - accuracy: 0.3333\n",
      "Epoch 4/200\n",
      "150/150 [==============================] - 0s 95us/step - loss: 1.1222 - accuracy: 0.3400\n",
      "Epoch 5/200\n",
      "150/150 [==============================] - 0s 128us/step - loss: 1.1032 - accuracy: 0.3400\n",
      "Epoch 6/200\n",
      "150/150 [==============================] - 0s 129us/step - loss: 1.0844 - accuracy: 0.3400\n",
      "Epoch 7/200\n",
      "150/150 [==============================] - 0s 240us/step - loss: 1.0666 - accuracy: 0.3467\n",
      "Epoch 8/200\n",
      "150/150 [==============================] - 0s 123us/step - loss: 1.0490 - accuracy: 0.3600\n",
      "Epoch 9/200\n",
      "150/150 [==============================] - 0s 167us/step - loss: 1.0323 - accuracy: 0.3800\n",
      "Epoch 10/200\n",
      "150/150 [==============================] - 0s 240us/step - loss: 1.0156 - accuracy: 0.4000\n",
      "Epoch 11/200\n",
      "150/150 [==============================] - 0s 173us/step - loss: 0.9996 - accuracy: 0.4533\n",
      "Epoch 12/200\n",
      "150/150 [==============================] - 0s 177us/step - loss: 0.9844 - accuracy: 0.5067\n",
      "Epoch 13/200\n",
      "150/150 [==============================] - 0s 38us/step - loss: 0.9695 - accuracy: 0.5533\n",
      "Epoch 14/200\n",
      "150/150 [==============================] - 0s 69us/step - loss: 0.9551 - accuracy: 0.5933\n",
      "Epoch 15/200\n",
      "150/150 [==============================] - 0s 85us/step - loss: 0.9409 - accuracy: 0.6067\n",
      "Epoch 16/200\n",
      "150/150 [==============================] - 0s 105us/step - loss: 0.9270 - accuracy: 0.6200\n",
      "Epoch 17/200\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.9142 - accuracy: 0.6467\n",
      "Epoch 18/200\n",
      "150/150 [==============================] - 0s 92us/step - loss: 0.9013 - accuracy: 0.6600\n",
      "Epoch 19/200\n",
      "150/150 [==============================] - 0s 34us/step - loss: 0.8886 - accuracy: 0.6600\n",
      "Epoch 20/200\n",
      "150/150 [==============================] - 0s 46us/step - loss: 0.8764 - accuracy: 0.6600\n",
      "Epoch 21/200\n",
      "150/150 [==============================] - 0s 84us/step - loss: 0.8640 - accuracy: 0.6600\n",
      "Epoch 22/200\n",
      "150/150 [==============================] - 0s 77us/step - loss: 0.8530 - accuracy: 0.6600\n",
      "Epoch 23/200\n",
      "150/150 [==============================] - 0s 83us/step - loss: 0.8422 - accuracy: 0.6600\n",
      "Epoch 24/200\n",
      "150/150 [==============================] - 0s 42us/step - loss: 0.8308 - accuracy: 0.6600\n",
      "Epoch 25/200\n",
      "150/150 [==============================] - 0s 36us/step - loss: 0.8202 - accuracy: 0.6600\n",
      "Epoch 26/200\n",
      "150/150 [==============================] - 0s 55us/step - loss: 0.8097 - accuracy: 0.6667\n",
      "Epoch 27/200\n",
      "150/150 [==============================] - 0s 49us/step - loss: 0.7993 - accuracy: 0.6667\n",
      "Epoch 28/200\n",
      "150/150 [==============================] - 0s 103us/step - loss: 0.7891 - accuracy: 0.6667\n",
      "Epoch 29/200\n",
      "150/150 [==============================] - 0s 64us/step - loss: 0.7792 - accuracy: 0.6667\n",
      "Epoch 30/200\n",
      "150/150 [==============================] - 0s 115us/step - loss: 0.7693 - accuracy: 0.6667\n",
      "Epoch 31/200\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.7595 - accuracy: 0.6667\n",
      "Epoch 32/200\n",
      "150/150 [==============================] - 0s 108us/step - loss: 0.7502 - accuracy: 0.6667\n",
      "Epoch 33/200\n",
      "150/150 [==============================] - 0s 156us/step - loss: 0.7416 - accuracy: 0.6667\n",
      "Epoch 34/200\n",
      "150/150 [==============================] - 0s 90us/step - loss: 0.7324 - accuracy: 0.6667\n",
      "Epoch 35/200\n",
      "150/150 [==============================] - 0s 180us/step - loss: 0.7241 - accuracy: 0.6667\n",
      "Epoch 36/200\n",
      "150/150 [==============================] - 0s 193us/step - loss: 0.7160 - accuracy: 0.6667\n",
      "Epoch 37/200\n",
      "150/150 [==============================] - 0s 109us/step - loss: 0.7075 - accuracy: 0.6667\n",
      "Epoch 38/200\n",
      "150/150 [==============================] - 0s 74us/step - loss: 0.6997 - accuracy: 0.6667\n",
      "Epoch 39/200\n",
      "150/150 [==============================] - 0s 50us/step - loss: 0.6918 - accuracy: 0.6667\n",
      "Epoch 40/200\n",
      "150/150 [==============================] - 0s 74us/step - loss: 0.6841 - accuracy: 0.6667\n",
      "Epoch 41/200\n",
      "150/150 [==============================] - 0s 59us/step - loss: 0.6764 - accuracy: 0.6667\n",
      "Epoch 42/200\n",
      "150/150 [==============================] - 0s 68us/step - loss: 0.6693 - accuracy: 0.6667\n",
      "Epoch 43/200\n",
      "150/150 [==============================] - 0s 30us/step - loss: 0.6621 - accuracy: 0.6667\n",
      "Epoch 44/200\n",
      "150/150 [==============================] - 0s 30us/step - loss: 0.6548 - accuracy: 0.6667\n",
      "Epoch 45/200\n",
      "150/150 [==============================] - 0s 35us/step - loss: 0.6482 - accuracy: 0.6667\n",
      "Epoch 46/200\n",
      "150/150 [==============================] - 0s 35us/step - loss: 0.6415 - accuracy: 0.6667\n",
      "Epoch 47/200\n",
      "150/150 [==============================] - 0s 77us/step - loss: 0.6350 - accuracy: 0.6667\n",
      "Epoch 48/200\n",
      "150/150 [==============================] - 0s 155us/step - loss: 0.6288 - accuracy: 0.6667\n",
      "Epoch 49/200\n",
      "150/150 [==============================] - 0s 89us/step - loss: 0.6227 - accuracy: 0.6667\n",
      "Epoch 50/200\n",
      "150/150 [==============================] - 0s 121us/step - loss: 0.6166 - accuracy: 0.6667\n",
      "Epoch 51/200\n",
      "150/150 [==============================] - 0s 99us/step - loss: 0.6109 - accuracy: 0.6667\n",
      "Epoch 52/200\n",
      "150/150 [==============================] - 0s 149us/step - loss: 0.6054 - accuracy: 0.6667\n",
      "Epoch 53/200\n",
      "150/150 [==============================] - 0s 84us/step - loss: 0.5999 - accuracy: 0.6667\n",
      "Epoch 54/200\n",
      "150/150 [==============================] - 0s 133us/step - loss: 0.5948 - accuracy: 0.6667\n",
      "Epoch 55/200\n",
      "150/150 [==============================] - 0s 56us/step - loss: 0.5897 - accuracy: 0.6667\n",
      "Epoch 56/200\n",
      "150/150 [==============================] - 0s 151us/step - loss: 0.5847 - accuracy: 0.6667\n",
      "Epoch 57/200\n",
      "150/150 [==============================] - 0s 131us/step - loss: 0.5800 - accuracy: 0.6667\n",
      "Epoch 58/200\n",
      "150/150 [==============================] - 0s 54us/step - loss: 0.5753 - accuracy: 0.6667\n",
      "Epoch 59/200\n",
      "150/150 [==============================] - 0s 84us/step - loss: 0.5708 - accuracy: 0.6667\n",
      "Epoch 60/200\n",
      "150/150 [==============================] - 0s 74us/step - loss: 0.5668 - accuracy: 0.6667\n",
      "Epoch 61/200\n",
      "150/150 [==============================] - 0s 99us/step - loss: 0.5627 - accuracy: 0.6667\n",
      "Epoch 62/200\n",
      "150/150 [==============================] - 0s 119us/step - loss: 0.5585 - accuracy: 0.6667\n",
      "Epoch 63/200\n",
      "150/150 [==============================] - 0s 111us/step - loss: 0.5549 - accuracy: 0.6667\n",
      "Epoch 64/200\n",
      "150/150 [==============================] - 0s 192us/step - loss: 0.5510 - accuracy: 0.6667\n",
      "Epoch 65/200\n",
      "150/150 [==============================] - 0s 165us/step - loss: 0.5474 - accuracy: 0.6667\n",
      "Epoch 66/200\n",
      "150/150 [==============================] - 0s 144us/step - loss: 0.5441 - accuracy: 0.6667\n",
      "Epoch 67/200\n",
      "150/150 [==============================] - 0s 207us/step - loss: 0.5407 - accuracy: 0.6667\n",
      "Epoch 68/200\n",
      "150/150 [==============================] - 0s 84us/step - loss: 0.5377 - accuracy: 0.6667\n",
      "Epoch 69/200\n",
      "150/150 [==============================] - 0s 144us/step - loss: 0.5345 - accuracy: 0.6667\n",
      "Epoch 70/200\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.5315 - accuracy: 0.6667\n",
      "Epoch 71/200\n",
      "150/150 [==============================] - 0s 42us/step - loss: 0.5285 - accuracy: 0.6667\n",
      "Epoch 72/200\n",
      "150/150 [==============================] - 0s 121us/step - loss: 0.5259 - accuracy: 0.6667\n",
      "Epoch 73/200\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.5231 - accuracy: 0.6667\n",
      "Epoch 74/200\n",
      "150/150 [==============================] - 0s 112us/step - loss: 0.5204 - accuracy: 0.6667\n",
      "Epoch 75/200\n",
      "150/150 [==============================] - 0s 165us/step - loss: 0.5180 - accuracy: 0.6667\n",
      "Epoch 76/200\n",
      "150/150 [==============================] - 0s 81us/step - loss: 0.5155 - accuracy: 0.6667\n",
      "Epoch 77/200\n",
      "150/150 [==============================] - 0s 70us/step - loss: 0.5133 - accuracy: 0.6667\n",
      "Epoch 78/200\n",
      "150/150 [==============================] - 0s 49us/step - loss: 0.5107 - accuracy: 0.6667\n",
      "Epoch 79/200\n",
      "150/150 [==============================] - 0s 77us/step - loss: 0.5087 - accuracy: 0.6667\n",
      "Epoch 80/200\n",
      "150/150 [==============================] - 0s 99us/step - loss: 0.5063 - accuracy: 0.6667\n",
      "Epoch 81/200\n",
      "150/150 [==============================] - 0s 106us/step - loss: 0.5042 - accuracy: 0.6667\n",
      "Epoch 82/200\n",
      "150/150 [==============================] - 0s 76us/step - loss: 0.5023 - accuracy: 0.6667\n",
      "Epoch 83/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.5735 - accuracy: 0.62 - 0s 193us/step - loss: 0.5001 - accuracy: 0.6667\n",
      "Epoch 84/200\n",
      "150/150 [==============================] - 0s 54us/step - loss: 0.4982 - accuracy: 0.6667\n",
      "Epoch 85/200\n",
      "150/150 [==============================] - 0s 54us/step - loss: 0.4964 - accuracy: 0.6667\n",
      "Epoch 86/200\n",
      "150/150 [==============================] - 0s 98us/step - loss: 0.4945 - accuracy: 0.6667\n",
      "Epoch 87/200\n",
      "150/150 [==============================] - 0s 54us/step - loss: 0.4927 - accuracy: 0.6667\n",
      "Epoch 88/200\n",
      "150/150 [==============================] - 0s 51us/step - loss: 0.4910 - accuracy: 0.6667\n",
      "Epoch 89/200\n",
      "150/150 [==============================] - 0s 86us/step - loss: 0.4895 - accuracy: 0.6667\n",
      "Epoch 90/200\n",
      "150/150 [==============================] - 0s 121us/step - loss: 0.4876 - accuracy: 0.6667\n",
      "Epoch 91/200\n",
      "150/150 [==============================] - 0s 39us/step - loss: 0.4859 - accuracy: 0.6667\n",
      "Epoch 92/200\n",
      "150/150 [==============================] - 0s 64us/step - loss: 0.4843 - accuracy: 0.6667\n",
      "Epoch 93/200\n",
      "150/150 [==============================] - 0s 74us/step - loss: 0.4827 - accuracy: 0.6667\n",
      "Epoch 94/200\n",
      "150/150 [==============================] - 0s 126us/step - loss: 0.4812 - accuracy: 0.6667\n",
      "Epoch 95/200\n",
      "150/150 [==============================] - 0s 165us/step - loss: 0.4798 - accuracy: 0.6667\n",
      "Epoch 96/200\n",
      "150/150 [==============================] - 0s 54us/step - loss: 0.4783 - accuracy: 0.6667\n",
      "Epoch 97/200\n",
      "150/150 [==============================] - 0s 83us/step - loss: 0.4768 - accuracy: 0.6667\n",
      "Epoch 98/200\n",
      "150/150 [==============================] - 0s 47us/step - loss: 0.4754 - accuracy: 0.6667\n",
      "Epoch 99/200\n",
      "150/150 [==============================] - 0s 108us/step - loss: 0.4741 - accuracy: 0.6667\n",
      "Epoch 100/200\n",
      "150/150 [==============================] - 0s 126us/step - loss: 0.4726 - accuracy: 0.6667\n",
      "Epoch 101/200\n",
      "150/150 [==============================] - 0s 129us/step - loss: 0.4714 - accuracy: 0.6667\n",
      "Epoch 102/200\n",
      "150/150 [==============================] - 0s 81us/step - loss: 0.4701 - accuracy: 0.6667\n",
      "Epoch 103/200\n",
      "150/150 [==============================] - 0s 155us/step - loss: 0.4687 - accuracy: 0.6667\n",
      "Epoch 104/200\n",
      "150/150 [==============================] - 0s 110us/step - loss: 0.4676 - accuracy: 0.6667\n",
      "Epoch 105/200\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.4662 - accuracy: 0.6667\n",
      "Epoch 106/200\n",
      "150/150 [==============================] - 0s 41us/step - loss: 0.4650 - accuracy: 0.6667\n",
      "Epoch 107/200\n",
      "150/150 [==============================] - 0s 84us/step - loss: 0.4639 - accuracy: 0.6733\n",
      "Epoch 108/200\n",
      "150/150 [==============================] - 0s 124us/step - loss: 0.4627 - accuracy: 0.6800\n",
      "Epoch 109/200\n",
      "150/150 [==============================] - 0s 99us/step - loss: 0.4615 - accuracy: 0.6800\n",
      "Epoch 110/200\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.4603 - accuracy: 0.6800\n",
      "Epoch 111/200\n",
      "150/150 [==============================] - 0s 139us/step - loss: 0.4593 - accuracy: 0.6800\n",
      "Epoch 112/200\n",
      "150/150 [==============================] - 0s 134us/step - loss: 0.4582 - accuracy: 0.6867\n",
      "Epoch 113/200\n",
      "150/150 [==============================] - 0s 170us/step - loss: 0.4572 - accuracy: 0.6867\n",
      "Epoch 114/200\n",
      "150/150 [==============================] - 0s 96us/step - loss: 0.4560 - accuracy: 0.6867\n",
      "Epoch 115/200\n",
      "150/150 [==============================] - 0s 125us/step - loss: 0.4549 - accuracy: 0.6867\n",
      "Epoch 116/200\n",
      "150/150 [==============================] - 0s 55us/step - loss: 0.4539 - accuracy: 0.6867\n",
      "Epoch 117/200\n",
      "150/150 [==============================] - 0s 41us/step - loss: 0.4531 - accuracy: 0.6867\n",
      "Epoch 118/200\n",
      "150/150 [==============================] - 0s 56us/step - loss: 0.4520 - accuracy: 0.6867\n",
      "Epoch 119/200\n",
      "150/150 [==============================] - 0s 65us/step - loss: 0.4508 - accuracy: 0.6867\n",
      "Epoch 120/200\n",
      "150/150 [==============================] - 0s 169us/step - loss: 0.4500 - accuracy: 0.6867\n",
      "Epoch 121/200\n",
      "150/150 [==============================] - 0s 108us/step - loss: 0.4489 - accuracy: 0.6933\n",
      "Epoch 122/200\n",
      "150/150 [==============================] - 0s 152us/step - loss: 0.4480 - accuracy: 0.6933\n",
      "Epoch 123/200\n",
      "150/150 [==============================] - 0s 101us/step - loss: 0.4469 - accuracy: 0.6933\n",
      "Epoch 124/200\n",
      "150/150 [==============================] - 0s 53us/step - loss: 0.4461 - accuracy: 0.6933\n",
      "Epoch 125/200\n",
      "150/150 [==============================] - 0s 109us/step - loss: 0.4451 - accuracy: 0.7000\n",
      "Epoch 126/200\n",
      "150/150 [==============================] - 0s 49us/step - loss: 0.4440 - accuracy: 0.7067\n",
      "Epoch 127/200\n",
      "150/150 [==============================] - 0s 155us/step - loss: 0.4432 - accuracy: 0.7133\n",
      "Epoch 128/200\n",
      "150/150 [==============================] - 0s 141us/step - loss: 0.4425 - accuracy: 0.7200\n",
      "Epoch 129/200\n",
      "150/150 [==============================] - 0s 76us/step - loss: 0.4415 - accuracy: 0.7267\n",
      "Epoch 130/200\n",
      "150/150 [==============================] - 0s 102us/step - loss: 0.4404 - accuracy: 0.7267\n",
      "Epoch 131/200\n",
      "150/150 [==============================] - 0s 141us/step - loss: 0.4396 - accuracy: 0.7267\n",
      "Epoch 132/200\n",
      "150/150 [==============================] - 0s 114us/step - loss: 0.4386 - accuracy: 0.7200\n",
      "Epoch 133/200\n",
      "150/150 [==============================] - 0s 39us/step - loss: 0.4376 - accuracy: 0.7200\n",
      "Epoch 134/200\n",
      "150/150 [==============================] - 0s 58us/step - loss: 0.4368 - accuracy: 0.7200\n",
      "Epoch 135/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.4386 - accuracy: 0.68 - 0s 58us/step - loss: 0.4359 - accuracy: 0.7200\n",
      "Epoch 136/200\n",
      "150/150 [==============================] - 0s 134us/step - loss: 0.4351 - accuracy: 0.7200\n",
      "Epoch 137/200\n",
      "150/150 [==============================] - 0s 135us/step - loss: 0.4341 - accuracy: 0.7200\n",
      "Epoch 138/200\n",
      "150/150 [==============================] - 0s 96us/step - loss: 0.4334 - accuracy: 0.7200\n",
      "Epoch 139/200\n",
      "150/150 [==============================] - 0s 134us/step - loss: 0.4322 - accuracy: 0.7200\n",
      "Epoch 140/200\n",
      "150/150 [==============================] - 0s 123us/step - loss: 0.4313 - accuracy: 0.7333\n",
      "Epoch 141/200\n",
      "150/150 [==============================] - 0s 68us/step - loss: 0.4306 - accuracy: 0.7467\n",
      "Epoch 142/200\n",
      "150/150 [==============================] - 0s 79us/step - loss: 0.4296 - accuracy: 0.7467\n",
      "Epoch 143/200\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.4287 - accuracy: 0.7600\n",
      "Epoch 144/200\n",
      "150/150 [==============================] - 0s 118us/step - loss: 0.4278 - accuracy: 0.7667\n",
      "Epoch 145/200\n",
      "150/150 [==============================] - 0s 143us/step - loss: 0.4269 - accuracy: 0.7800\n",
      "Epoch 146/200\n",
      "150/150 [==============================] - 0s 116us/step - loss: 0.4260 - accuracy: 0.7800\n",
      "Epoch 147/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.4215 - accuracy: 0.71 - 0s 295us/step - loss: 0.4250 - accuracy: 0.7667\n",
      "Epoch 148/200\n",
      "150/150 [==============================] - 0s 174us/step - loss: 0.4242 - accuracy: 0.7800\n",
      "Epoch 149/200\n",
      "150/150 [==============================] - 0s 162us/step - loss: 0.4232 - accuracy: 0.7800\n",
      "Epoch 150/200\n",
      "150/150 [==============================] - 0s 190us/step - loss: 0.4223 - accuracy: 0.7800\n",
      "Epoch 151/200\n",
      "150/150 [==============================] - 0s 83us/step - loss: 0.4212 - accuracy: 0.7800\n",
      "Epoch 152/200\n",
      "150/150 [==============================] - 0s 114us/step - loss: 0.4204 - accuracy: 0.7800\n",
      "Epoch 153/200\n",
      "150/150 [==============================] - 0s 154us/step - loss: 0.4194 - accuracy: 0.7800\n",
      "Epoch 154/200\n",
      "150/150 [==============================] - 0s 115us/step - loss: 0.4185 - accuracy: 0.7867\n",
      "Epoch 155/200\n",
      "150/150 [==============================] - 0s 128us/step - loss: 0.4175 - accuracy: 0.7867\n",
      "Epoch 156/200\n",
      "150/150 [==============================] - 0s 145us/step - loss: 0.4165 - accuracy: 0.7867\n",
      "Epoch 157/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 104us/step - loss: 0.4155 - accuracy: 0.8067\n",
      "Epoch 158/200\n",
      "150/150 [==============================] - 0s 32us/step - loss: 0.4144 - accuracy: 0.8067\n",
      "Epoch 159/200\n",
      "150/150 [==============================] - 0s 88us/step - loss: 0.4136 - accuracy: 0.8067\n",
      "Epoch 160/200\n",
      "150/150 [==============================] - 0s 143us/step - loss: 0.4127 - accuracy: 0.7867\n",
      "Epoch 161/200\n",
      "150/150 [==============================] - 0s 121us/step - loss: 0.4115 - accuracy: 0.8000\n",
      "Epoch 162/200\n",
      "150/150 [==============================] - 0s 123us/step - loss: 0.4105 - accuracy: 0.8067\n",
      "Epoch 163/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.4138 - accuracy: 0.84 - 0s 122us/step - loss: 0.4096 - accuracy: 0.8200\n",
      "Epoch 164/200\n",
      "150/150 [==============================] - 0s 114us/step - loss: 0.4083 - accuracy: 0.8200\n",
      "Epoch 165/200\n",
      "150/150 [==============================] - 0s 58us/step - loss: 0.4073 - accuracy: 0.8200\n",
      "Epoch 166/200\n",
      "150/150 [==============================] - 0s 46us/step - loss: 0.4065 - accuracy: 0.8200\n",
      "Epoch 167/200\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.4055 - accuracy: 0.8200\n",
      "Epoch 168/200\n",
      "150/150 [==============================] - 0s 148us/step - loss: 0.4041 - accuracy: 0.8467\n",
      "Epoch 169/200\n",
      "150/150 [==============================] - 0s 164us/step - loss: 0.4030 - accuracy: 0.8467\n",
      "Epoch 170/200\n",
      "150/150 [==============================] - 0s 156us/step - loss: 0.4021 - accuracy: 0.8467\n",
      "Epoch 171/200\n",
      "150/150 [==============================] - 0s 134us/step - loss: 0.4009 - accuracy: 0.8467\n",
      "Epoch 172/200\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.4000 - accuracy: 0.8600\n",
      "Epoch 173/200\n",
      "150/150 [==============================] - 0s 55us/step - loss: 0.3986 - accuracy: 0.8600\n",
      "Epoch 174/200\n",
      "150/150 [==============================] - 0s 124us/step - loss: 0.3976 - accuracy: 0.8600\n",
      "Epoch 175/200\n",
      "150/150 [==============================] - 0s 166us/step - loss: 0.3964 - accuracy: 0.8600\n",
      "Epoch 176/200\n",
      "150/150 [==============================] - 0s 120us/step - loss: 0.3951 - accuracy: 0.8600\n",
      "Epoch 177/200\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.3940 - accuracy: 0.8600\n",
      "Epoch 178/200\n",
      "150/150 [==============================] - 0s 54us/step - loss: 0.3928 - accuracy: 0.8600\n",
      "Epoch 179/200\n",
      "150/150 [==============================] - 0s 59us/step - loss: 0.3917 - accuracy: 0.8600\n",
      "Epoch 180/200\n",
      "150/150 [==============================] - 0s 114us/step - loss: 0.3903 - accuracy: 0.8600\n",
      "Epoch 181/200\n",
      "150/150 [==============================] - 0s 108us/step - loss: 0.3891 - accuracy: 0.8667\n",
      "Epoch 182/200\n",
      "150/150 [==============================] - 0s 97us/step - loss: 0.3880 - accuracy: 0.8667\n",
      "Epoch 183/200\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.3865 - accuracy: 0.8733\n",
      "Epoch 184/200\n",
      "150/150 [==============================] - 0s 131us/step - loss: 0.3854 - accuracy: 0.8733\n",
      "Epoch 185/200\n",
      "150/150 [==============================] - 0s 142us/step - loss: 0.3841 - accuracy: 0.8867\n",
      "Epoch 186/200\n",
      "150/150 [==============================] - 0s 64us/step - loss: 0.3829 - accuracy: 0.8933\n",
      "Epoch 187/200\n",
      "150/150 [==============================] - 0s 65us/step - loss: 0.3815 - accuracy: 0.8933\n",
      "Epoch 188/200\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.3805 - accuracy: 0.8867\n",
      "Epoch 189/200\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.3790 - accuracy: 0.8867\n",
      "Epoch 190/200\n",
      "150/150 [==============================] - 0s 113us/step - loss: 0.3775 - accuracy: 0.8867\n",
      "Epoch 191/200\n",
      "150/150 [==============================] - 0s 99us/step - loss: 0.3763 - accuracy: 0.8933\n",
      "Epoch 192/200\n",
      "150/150 [==============================] - 0s 116us/step - loss: 0.3749 - accuracy: 0.8933\n",
      "Epoch 193/200\n",
      "150/150 [==============================] - 0s 137us/step - loss: 0.3736 - accuracy: 0.8933\n",
      "Epoch 194/200\n",
      "150/150 [==============================] - 0s 127us/step - loss: 0.3722 - accuracy: 0.8933\n",
      "Epoch 195/200\n",
      "150/150 [==============================] - 0s 59us/step - loss: 0.3708 - accuracy: 0.8933\n",
      "Epoch 196/200\n",
      "150/150 [==============================] - 0s 83us/step - loss: 0.3694 - accuracy: 0.8933\n",
      "Epoch 197/200\n",
      "150/150 [==============================] - 0s 118us/step - loss: 0.3679 - accuracy: 0.8933\n",
      "Epoch 198/200\n",
      "150/150 [==============================] - 0s 65us/step - loss: 0.3666 - accuracy: 0.8933\n",
      "Epoch 199/200\n",
      "150/150 [==============================] - 0s 45us/step - loss: 0.3652 - accuracy: 0.8933\n",
      "Epoch 200/200\n",
      "150/150 [==============================] - 0s 81us/step - loss: 0.3637 - accuracy: 0.8933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f23f623ff10>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X,y,epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model/iris.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./scaler/iris_scaler.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(scaler,'./scaler/iris_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_model = load_model('./model/iris.h5')\n",
    "flower_scaler = joblib.load(\"./scaler/iris_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_temp = {\"sepal_length\":5.1,\n",
    "              \"sepal_width\":3.5,\n",
    "              \"petal_length\":1.4,\n",
    "              \"petal_width\":0.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype='<U15')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    " def return_prediction(model,scaler,sample_json):\n",
    "        s_len = sample_json[\"sepal_length\"]\n",
    "        s_wid = sample_json[\"sepal_width\"]\n",
    "        p_len = sample_json[\"petal_length\"]\n",
    "        p_wid = sample_json[\"petal_width\"]\n",
    "        classes = np.array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'])\n",
    "        flower = [[s_len,s_wid,p_len,p_wid]]\n",
    "        flower = scaler.transform(flower)\n",
    "        class_ind = model.predict_classes(flower)[0]\n",
    "        return classes[class_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iris-setosa'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_prediction(flower_model, flower_scaler,flower_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
